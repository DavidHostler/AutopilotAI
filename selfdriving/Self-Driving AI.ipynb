{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ab1dca",
   "metadata": {},
   "source": [
    "### This notebook chronicles the development of a myopic time-series model for running your vehicle on autopilot in a game such as GTA 5 or Forza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea2375",
   "metadata": {},
   "source": [
    "# THEORY:\n",
    "\n",
    "### Recurrent LSTM networks are fairly good at predicting on time series data. However, I've made a slight mathematical adjustment to the recurrent training data- instead of training the model on a series of discrete data points indicating net displacement, I've augmented the data to represent a series of Gaussian distributions centred around the ground-truth value from the original dataset.\n",
    "\n",
    "### This has a few properties: \n",
    "\n",
    "### (1) The predictions Y_n are a function of a randomly sampled value Y_n-1; in the limit as the amount of such recurrent samples approaches infinity, the distribution of training data becomes a Gaussian distribution function. Through integral calculus, it can be shown that the expectation value of each distribution is equal to the value before the one being predicted. This allows us to model our time series data as a martingale, which is fitting since noisy data undergoes geometric brownian motion, and enables us to regularise the data to many possible outcomes as a result, i.e. order from chaos. \n",
    "\n",
    "### (2) Since the data is a martingale AND a Gaussian process, using Baye's theorem for several joint probabilities, it can be shown that the logarithm of the probability of predicting a certain value does in fact vary proportionally to the expectation value of the mean-squared-loss function from linear regression models. \n",
    "\n",
    "### TL;DR Applying a regularization technique from variational autoencoders to a LSTM model allows us to take advantage of the recurrent  nature of the model to basically train it on a martingale, and then because of how the math works out (pen and paper wise), can be treated as a regular problem just by using a mean-squared-error loss function. Additionally, because Gaussians are continuous and infinitely differentiable (although they don't have the nicest derivatives), I'm led to believe that backpropagation will train the network using information from these Gaussians and hence generalize the model to adapt to them more in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26583405",
   "metadata": {},
   "source": [
    "# APPLICATION: \n",
    "\n",
    "### What we have is a time series model to predict the behaviour of a car in 2 dimensions. Assuming that a video game obeys most of the laws of classical mechanics, it should suffice to calculate things like velocity and acceleration by computing first and second order derivatives of the position in 2D.\n",
    "\n",
    "### The ML model predicts the components of acceleration in the plane of the road when activated. While 'inactive', the model is training in the background on keylogger data. This is done simultaneously via implementing both the model and a keylogger via python's multithreading module. The force is (assumed) constant, and when the user leaves his chair to accept a pizza at the front door, the keylogger will detect that there has been no user input for long enough that autopilot kicks in!\n",
    "\n",
    "### The network determines based on Gaussians centred around recent driving data what keys to press, i.e. hit the brakes or gas, right or left turn holds. Granted, in this naive form, the car is able to predict human driving patterns-but it is completely blind. The assumption is that you have enough time to answer the door, return and hopefully you haven't crashed! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "964d8d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pipeline has 3 parts:\n",
    "\n",
    "#2 Model training threads\n",
    "\n",
    "#Keylogging thread \n",
    "\n",
    "#Model deployment thread "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "465b4ea7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyautogui'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyautogui\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyautogui'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "638a83c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyautogui\n",
      "  Using cached PyAutoGUI-0.9.53.tar.gz (59 kB)\n",
      "Collecting pymsgbox\n",
      "  Using cached PyMsgBox-1.0.9.tar.gz (18 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting PyTweening>=1.0.1\n",
      "  Using cached pytweening-1.0.4.tar.gz (14 kB)\n",
      "Collecting pyscreeze>=0.1.21\n",
      "  Using cached PyScreeze-0.1.28.tar.gz (25 kB)\n",
      "^C\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hcanceled\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ca153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#Time Series Machine Learning Based\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout  \n",
    "from keras.models import Sequential \n",
    "import tensorflow as tf\n",
    "#Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c5f35c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import time \n",
    "import os\n",
    "import random\n",
    "from pynput.keyboard import Key, Listener, KeyCode\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "570c30e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dolan/Desktop/DataScience/selfdriving/'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = os.getcwd() + '/'\n",
    "logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87d9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe105612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key.down\n",
      "0.0013761520385742188\n",
      "Key.up\n",
      "0.0001418590545654297\n",
      "Key.down\n",
      "0.00020575523376464844\n",
      "Key.up\n",
      "0.0001533031463623047\n",
      "Key.up\n",
      "0.00017499923706054688\n",
      "Key.down\n",
      "0.0001316070556640625\n",
      "Key.up\n",
      "0.000171661376953125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#if key == Key.esc:\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# return false\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Listener(on_press \u001b[38;5;241m=\u001b[39m onPress) \u001b[38;5;28;01mas\u001b[39;00m listener:\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mlistener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pynput/_util/__init__.py:269\u001b[0m, in \u001b[0;36mAbstractListener.join\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAbstractListener\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# Reraise any exceptions\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/threading.py:1053\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1053\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/threading.py:1073\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1074\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1075\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "array = []\n",
    "\n",
    "\n",
    "def onPress(key):\n",
    "    global array\n",
    "    a = KeyCode.from_char(\"a\")\n",
    "    logging.info(str(key))\n",
    "    array.append(key)\n",
    "    start = time.time()\n",
    "    if key == Key.esc:\n",
    "        return False\n",
    "    elif key == a:\n",
    "        print('Hooray!')\n",
    "    else:\n",
    "        print(key)\n",
    "    print(time.time() - start)\n",
    "    \n",
    "    #if key == Key.esc:\n",
    "    # return false\n",
    "with Listener(on_press = onPress) as listener:\n",
    "    listener.join() \n",
    "    #listener.append()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d89758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cd62aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5df64f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val = array[-1]\n",
    "if str(val) == 'a':\n",
    "    print('yay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cab0eaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooray\n"
     ]
    }
   ],
   "source": [
    "test = KeyCode.from_char(\"a\")\n",
    "if array[-1] == test:\n",
    "    print('Hooray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e219ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d97edbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa1ccc10",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "info() missing 1 required positional argument: 'msg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: info() missing 1 required positional argument: 'msg'"
     ]
    }
   ],
   "source": [
    "logging.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a044155",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fizz buzz0 0\n",
      "fizz \n",
      "buzz1 \n",
      "fizz1 \n",
      "2\n",
      "buzzfizz 3 2\n",
      "\n",
      "fizz buzz 43\n",
      "fizz 5\n",
      "fizz 6\n",
      "\n",
      "buzzfizz 4\n",
      "buzz 5\n",
      "buzz  67\n",
      "\n",
      "fizzbuzz  87\n",
      "\n",
      "fizzbuzz 8 \n",
      "9buzz\n",
      " 9\n"
     ]
    }
   ],
   "source": [
    "#Multithreading practice example\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def fizz():\n",
    "    global counter \n",
    "    while counter < 10:\n",
    "        print('fizz', counter)\n",
    "        counter += 1\n",
    "def buzz():\n",
    "    global counter \n",
    "    while counter < 10:\n",
    "        print('buzz', counter)\n",
    "        counter += 1\n",
    "p1 = Process(target = fizz)\n",
    "p1.start()\n",
    "p2 = Process(target = buzz)\n",
    "p2.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1e4a653b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Vehicle:\n",
    "    \n",
    "    def __init__(self, memory_window_size, model):\n",
    "        self.latest_vx = 0.0\n",
    "        self.latest_vy = 0.0 #2D velocity components\n",
    "        '''In order to have up-to-data training data, the two arrays must be QUEUES.\n",
    "        The oldest information needs to be forgotten first, so pop from the front of each every time\n",
    "        a new value is added to the velocity data for the graph.\n",
    "        \n",
    "        #Assumption is that by cumulatively adding increments of the acceleration with each keypress,\n",
    "        the sum in the onPress function effectively numerically integrates the acceleration wrt time,\n",
    "        i,e. += 1.0 * alpha, our incremental change in time (although we should adjust this by finding differences\n",
    "        in Unix time!)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        self.model = model\n",
    "        self.history = None\n",
    "        self.vx = [] #Update this parameter with new values each time\n",
    "        self.vy = []\n",
    "        \n",
    "        self.X_horizontal = None\n",
    "        self.y_horizontal = None\n",
    "        \n",
    "        self.X_vertical = None\n",
    "        self.y_vertical = None\n",
    "        \n",
    "        self.memory_window_size = memory_window_size\n",
    "        \n",
    "        self.X_horizontal, self.y_horizontal = [0] * memory_window_size , [0] * memory_window_size\n",
    "        self.X_vertical, self.y_vertical  = [0] * memory_window_size , [0] * memory_window_size\n",
    "\n",
    "        \n",
    "        \n",
    "        self.time_elapsed = 0.0\n",
    "        \n",
    "    def onPress(self, key, alpha=0.1):\n",
    "        logging.info(str(key))\n",
    "        w = KeyCode.from_char(\"w\")\n",
    "        s = KeyCode.from_char(\"s\")\n",
    "        d = KeyCode.from_char(\"d\")\n",
    "        a = KeyCode.from_char(\"a\")\n",
    "        #training_thread = process(target=self.train)\n",
    "        #Generate velocity-time data by numerically integrating acceleration over each keypress timestep\n",
    "        start = time.time()\n",
    "        self.key = key\n",
    "        if self.key == w:\n",
    "            self.latest_vy += 1.0 * alpha #dv = adt\n",
    "            self.vy.append(self.latest_vy)\n",
    "        elif self.key == s:\n",
    "            self.latest_vy -= 1.0 * alpha\n",
    "            self.vy.append(self.latest_vy)\n",
    "        elif self.key == d:\n",
    "            self.latest_vx += 1.0 * alpha\n",
    "            self.vx.append(self.latest_vx)\n",
    "        elif self.key == a:\n",
    "            self.latest_ax -= 1.0 * alpha\n",
    "            self.vx.append(self.latest_vx)\n",
    "        elif self.key == Key.esc:\n",
    "            self.time_elapsed = 0.0\n",
    "            return false\n",
    "        alpha = time.time() - start #Calculate delta_t for numerical integrals\n",
    "        \n",
    "    def listen(self, called=False):\n",
    "        p = KeyCode.from_char(\"p\")\n",
    "        if called is True:\n",
    "            with Listener(on_press = self.onPress) as listener:\n",
    "\n",
    "                listener.join() \n",
    "                listener.append()  \n",
    "    \n",
    "    \n",
    "    def gaussian_noise(self, value, num_noise_pts=100):\n",
    "        sigma = random.uniform(0, 1) \n",
    "        return np.random.normal(value, sigma,(num_noise_pts, value.shape[0])) #standard deviation can be obtained more accu \n",
    "\n",
    "    def generate_gaussian_training_data(self, memory_window_size=1000):  \n",
    "#         for i in range(1,len(vx)):\n",
    "        \n",
    "        #Add new data to training set, and pop outdated data from the front \n",
    "        self.X_horizontal.append(self.gaussian_noise(self.vx[i-1]))\n",
    "        self.y_horizontal.append(self.vx[i])\n",
    "        self.X_horizontal.pop(0), y_horizontal.pop(0)\n",
    "        \n",
    "        self.X_vertical.append(self.gaussian_noise(self.vy[i-1]))\n",
    "        self.y_vertical.append(self.vy[i])\n",
    "        \n",
    "        self.X_vertical.pop(0), self.y_vertical(0)\n",
    "        \n",
    "        self.X_horizontal, self.y_horizontal = np.array(self.X_horizontal), np.array(self.y_horizontal)\n",
    "        self.X_vertical, self.y_vertical = np.array(self.X_vertical), np.array(self.y_vertical)\n",
    "        \n",
    "        self.X_horizontal = self.X_horizontal/np.max(self.X_horizontal)\n",
    "        self.y_horizontal = self.y_horizontal/np.max(self.y_horizontal)\n",
    "        \n",
    "        self.X_vertical = self.X_vertical/np.max(X_vertical)\n",
    "        self.y_vertical = self.y_vertical/np.max(y_vertical)\n",
    "    \n",
    "    def autopilot(self, timestep=0.0015):\n",
    "        '''Generate a Gaussians every timestep centred around the \n",
    "        previously predicted value if evaluating in real time.\n",
    "        '''\n",
    "        X_horiz_eval = self.gaussian_noise(self.X_horizontal[-1])\n",
    "        X_vert_eval = self.gaussian_noise(self.X_vertical[-1])\n",
    "        \n",
    "        predicted_x = model.predict(np.expand_dims(X_horiz_eval))  \n",
    "        predicted_y = model.predict(np.expand_dims(X_vert_eval))  \n",
    "        \n",
    "        if predicted_x > 0.0:\n",
    "            pyautogui.press('d')\n",
    "        elif predicted_x < 0.0:\n",
    "            pyautogui.press('a')\n",
    "        else:\n",
    "            pass\n",
    "        if predicted_y > 0.0:\n",
    "            pyautogui.press('w')\n",
    "        elif predicted_y < 0.0:\n",
    "            pyautogui.press('s')\n",
    "        else:\n",
    "            pass \n",
    "        \n",
    "    def go_gadget_go(self): #Activate the operational loop of the model using \n",
    "                            #multithreading...\n",
    "        \n",
    "        \n",
    "        if self.key == Keycode.from_char(\"p\"):\n",
    "            keylogger = Process(target=self.listen)\n",
    "            neural_net = Process(target=self.autopilot)\n",
    "            \n",
    "            keylogger.start()\n",
    "            \n",
    "            \n",
    "            neural_net.start()\n",
    "        \n",
    "            keylogger.join()\n",
    "            neural_net.join()\n",
    "        if self.key == KeyCode.from_char(\"o\"):\n",
    "            \n",
    "            neural_net.terminate() #Terminate the AI-prediction-based process\n",
    "                                   #Sounded \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab1b5b3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m car \u001b[38;5;241m=\u001b[39m \u001b[43mVehicle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'model'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2332d4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The input data should have shape (car.memory_size_window, num_noise_pts=100, 1)\n",
    "'''For unseen future data, a Gaussian distribution function should be used to iteratively generate the next \n",
    "Gaussian distribution as a function of the value of the last prediction, i.e. training data as a function of \n",
    "time should be considered a martingale. That is for each timestep, generate the next distribution as a \n",
    "Gaussian centred around the previous data point.\n",
    "\n",
    "#Maybe also just pretrain the recurrent LSTM and deploy it live only if needed... we don't need this portfolio \n",
    "project to turn into a PhD thesis :)\n",
    "\n",
    "#If the model is pretrained on a sufficiently large time window, simply use the above generator function to create \n",
    "the next Gaussian distribution of random data, set X_test = np.expand_dims(X_test, axis=0) to reshape it for \n",
    "single unit data inputs (for one unit of training data in this case the Gaussian distr) and then use model.predict\n",
    "\n",
    "'''\n",
    "model = Sequential()\n",
    "#100 for the 100 noise points attributed to each Gaussian distr\n",
    "model.add(LSTM(units=100, return_sequences=True,input_shape=(100, 1)))#X_train.shape[1:]\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "998295c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "741bf9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To train two models concurrently while running the keylogger simultaneously, \n",
    "\n",
    "#we likely need to train the model using the GradientTape method.\n",
    "\n",
    "#Write a training loop from scratch and update all parameters, train the models and if AFK, \n",
    "\n",
    "#Run a model.predict function on the future data. #Ofc, because it is trained on a series of Gaussians, \n",
    "\n",
    "#we could just generate random Gaussians with random means (itself a Gaussian process!) and simply give them\n",
    "\n",
    "#extremely wide variances so that we can predict these random clusters for input to the model as a function of \n",
    "\n",
    "#time.\n",
    "car = Vehicle(100, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0ff93be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 100, 100)          40800     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 100, 100)          0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 100, 150)          150600    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 100, 150)          0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 100, 150)          180600    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 100, 150)          0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 100, 150)          180600    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 100, 150)          0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 100, 150)          180600    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 100, 150)          0         \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 150)               180600    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 150)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 151       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 913,951\n",
      "Trainable params: 913,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# car.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd75132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d32d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bea3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78dea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a3286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
